{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04887c64",
   "metadata": {},
   "source": [
    "#### **3. Response Generation Task:**\n",
    "* In this notebook, I have performed a response generation task using **Retrieval-Augmented Generation (RAG)**. This RAG-based response generation is implemented using a locally installed LLM and text embedding models via Ollama. Specifically, I used **llama3.1:8b** as the LLM and **mxbai-embed-large** as the text embedding model.\n",
    "\n",
    "* **Step 1:** To build the RAG-based response generation system, I used a fraction (0.5%) of the `filtered_enron_emails.csv` dataset as the knowledge base. I chose only 0.5% of the data due to memory and computation constraints.\n",
    "\n",
    "* **Step 2:** I chunked the knowledge base data into segments of 500 characters with an overlap of 50 characters.\n",
    "\n",
    "* **Step 3:** These chunks were converted into vector embeddings using the `mxbai-embed-large` model (which outputs 1024-dimensional vectors) and stored in an on-disk `Faiss-Index`.\n",
    "\n",
    "* **Step 4:** Based on a given query, similar documents were retrieved from the `Faiss index`. Using prompt engineering techniques, I then generated responses with the help of the LLM `llama3.1:8b`. All steps are systematically demonstrated in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv('../data/filtered_enron_emails.csv')\n",
    "sampled_df = df.sample(frac=0.005, random_state=47).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eeaf942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents with len >= 500: 863\n"
     ]
    }
   ],
   "source": [
    "#Filter emails where body length >= 500 characters\n",
    "filtered_docs = sampled_df['body'].dropna()\n",
    "filtered_docs = filtered_docs[filtered_docs.str.len() >= 500].tolist()\n",
    "\n",
    "# Now filtered_docs contains each email body (≥ 500 chars) as a single document\n",
    "print(f\"Total documents with len >= 500: {len(filtered_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform chuck creation using RecursiveCharacterTextSplitter \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,  # slight overlap preserves context\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],  # smart fallback if no newlines\n",
    ")\n",
    "\n",
    "docs = splitter.create_documents(filtered_docs)\n",
    "chunks = [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcea6c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb79d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I'm generating embeddings for each text chunk in parallel \n",
    "# by utilizing multiple CPU cores. This speeds up the process by \n",
    "# running several embedding requests at the same time.\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "def get_ollama_embedding(text, model=\"mxbai-embed-large\"):\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/embeddings\",\n",
    "        json={\"model\": model, \"prompt\": text}\n",
    "    )\n",
    "    return response.json()[\"embedding\"]\n",
    "\n",
    "def embed_chunks_parallel(chunks, max_workers=10):\n",
    "    embeddings = [None] * len(chunks)\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(get_ollama_embedding, chunk): idx\n",
    "            for idx, chunk in enumerate(chunks)\n",
    "        }\n",
    "        for future in tqdm(as_completed(futures), total=len(chunks), desc=\"Embedding chunks\"):\n",
    "            idx = futures[future]\n",
    "            try:\n",
    "                embeddings[idx] = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Chunk {idx} failed: {e}\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb1c9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "class OllamaEmbeddingFunction(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        embeddings = []\n",
    "        for text in tqdm(texts, desc=\"Embedding via Ollama\"):\n",
    "            response = requests.post(\n",
    "                \"http://localhost:11434/api/embeddings\",\n",
    "                json={\"model\": \"mxbai-embed-large\", \"prompt\": text}\n",
    "            )\n",
    "            embeddings.append(response.json()[\"embedding\"])\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/embeddings\",\n",
    "            json={\"model\": \"mxbai-embed-large\", \"prompt\": text}\n",
    "        )\n",
    "        return response.json()[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4634415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding chunks: 100%|██████████| 7600/7600 [32:10<00:00,  3.94it/s]  \n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Step 1: Create documents\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Step 2: Embed in parallel\n",
    "# # Adjust workers for your CPU/GPU\n",
    "chunk_embeddings = embed_chunks_parallel(chunks, max_workers=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838e8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a instance of OllamaEmbeddingFunction\n",
    "embedding_func = OllamaEmbeddingFunction() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.docstore.document import Document\n",
    "import numpy as np\n",
    "import faiss \n",
    "\n",
    "# Step 1: Convert to float32 numpy array\n",
    "embedding_vectors = np.array(chunk_embeddings).astype(\"float32\")\n",
    "\n",
    "# Step 2: Create FAISS index\n",
    "dimension = embedding_vectors.shape[1]  ## 1024 - dimensions\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(embedding_vectors)\n",
    "\n",
    "# Step 3: Wrap documents\n",
    "docstore = InMemoryDocstore(dict(enumerate(documents)))\n",
    "index_to_docstore_id = {i: i for i in range(len(documents))}\n",
    "\n",
    "# Step 4: Create the vectorstore\n",
    "vectorstore = FAISS(\n",
    "    index=faiss_index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id,\n",
    "    embedding_function=embedding_func\n",
    ")\n",
    "\n",
    "# Step 5: Save the index\n",
    "vectorstore.save_local(\"../faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95a15cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7600, 1024)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b49e43",
   "metadata": {},
   "source": [
    "##### **Inferencing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c73c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously saved FAISS index from disk so we can use it for searching (inference).\n",
    "from langchain.vectorstores import FAISS \n",
    "\n",
    "faiss_index = FAISS.load_local(\n",
    "    folder_path=\"../faiss_index\",\n",
    "    embeddings=embedding_func,\n",
    "    allow_dangerous_deserialization=True  # safe only if file is trusted\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa891227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve simmilar docs based on query\n",
    "def retrieve_similar_docs(query, faiss_index, top_k=3):\n",
    "    query_embedding = get_ollama_embedding(query)\n",
    "    results = faiss_index.similarity_search_by_vector(query_embedding, k=top_k)\n",
    "    return results  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d008fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Subject: Urgent: Immediate Response Required on Q2 Budget Approval for Mumbai Project\n",
    "\n",
    "Dear Anita Sharma,\n",
    "\n",
    "I hope you’re doing well.\n",
    "\n",
    "I’m writing to urgently follow up on the Q2 budget approval for the Mumbai Expansion Project, which was discussed in last week’s leadership meeting. As per the timeline, we need the final approved figures by 4:00 PM today (June 1st) to proceed with vendor onboarding and contract finalization.\n",
    "\n",
    "Could you please confirm the approval status or share the signed document at the earliest? The operations team in Mumbai is on standby and any delay might impact the kickoff scheduled for Monday, June 3rd.\n",
    "\n",
    "Your immediate attention to this matter is greatly appreciated.\n",
    "\n",
    "Warm regards,\n",
    "Ravi Menon\n",
    "Project Manager – South Zone\n",
    "ABC Infrastructure Pvt. Ltd.\n",
    "\"\"\"\n",
    "similar_docs = retrieve_similar_docs(query, faiss_index)\n",
    "\n",
    "context = \"\\n---\\n\".join([doc.page_content for doc in similar_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daa074ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"thanks for the note. good work. if i am in mumbai for a full day on friday, 4 august, is that sufficient thanks mcs jane wilsonenrondevelopment 26072000 1840 to mark schroederect, wade clineenrondevelopmentenrondevelopment cc subject comments to mop worked the ministry of power yesterday with sanjay and had my own meeting with the junior secretary who is in charge of the electricity bill effort. he invited me back\\n---\\nshall i handle items 1 and 2 kay  forwarded by kay manncorpenron on 10232000 0853 am  from roseann engeldorf on 10232000 0852 am to sheila tweedhouectect cc kay manncorpenronenron, lisa billscorpenronenron, brenda l funkhouectect subject csfb financing  na power projects sheila, as i mentioned in my voice mail, there are a couple of items i need to follow up with you on 1. turbine purchase agreements  diligence item for the bank. i have most of these, i think\\n---\\ndidn't know orig was granted. will book today. thanks. if you're available, i'd like to get together early this week to talk about whether we think there's value in going forward with develop efforts. mitch original message from kitchen, louise sent friday, july 06, 2001 345 pm to robinson, mitch subject re loretta pricing did you book your one million granted orig from john  if not, please make sure you do quickly\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e74e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, context):\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant. Use the context below to answer or generate response of common email types.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Instruction:\n",
    "    {query}\n",
    "\n",
    "    Response:\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": \"llama3.1:8b\", \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    \n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e62277f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Subject: Urgent: Immediate Response Required on Q2 Budget Approval for Mumbai Project\n",
    "\n",
    "Dear Anita Sharma,\n",
    "\n",
    "I hope you’re doing well.\n",
    "\n",
    "I’m writing to urgently follow up on the Q2 budget approval for the Mumbai Expansion Project, which was discussed in last week’s leadership meeting. As per the timeline, we need the final approved figures by 4:00 PM today (June 1st) to proceed with vendor onboarding and contract finalization.\n",
    "\n",
    "Could you please confirm the approval status or share the signed document at the earliest? The operations team in Mumbai is on standby and any delay might impact the kickoff scheduled for Monday, June 3rd.\n",
    "\n",
    "Your immediate attention to this matter is greatly appreciated.\n",
    "\n",
    "Warm regards,\n",
    "Ravi Menon\n",
    "Project Manager – South Zone\n",
    "ABC Infrastructure Pvt. Ltd.\n",
    "\"\"\"\n",
    "\n",
    "similar_docs = retrieve_similar_docs(query, faiss_index)\n",
    "\n",
    "context = \"\\n---\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "response = generate_answer(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33943f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: Urgent: Immediate Response Required on Q2 Budget Approval for Mumbai Project\n",
      "\n",
      "Dear Ravi,\n",
      "\n",
      "Thank you for your email. I've checked with our finance team, and they have confirmed that the Q2 budget approval is still pending. They are working on finalizing the numbers and expect to have a revised version ready by tomorrow (June 2nd) morning.\n",
      "\n",
      "I recommend we schedule a call at 10:00 AM tomorrow to review the latest figures and ensure everything is in order for the Mumbai project kickoff. This will also give us an opportunity to discuss any potential risks or concerns before proceeding with vendor onboarding and contract finalization.\n",
      "\n",
      "Please let me know if this time slot works for you, and I'll send out a formal invite to our team members involved in the project.\n",
      "\n",
      "Best regards,\n",
      "Anita Sharma\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "288bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30a31e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Subject: Re: Urgent: Immediate Response Required on Q2 Budget Approval for Mumbai Project\n",
       "\n",
       "Dear Ravi,\n",
       "\n",
       "Thank you for your email. I've checked with our finance team, and they have confirmed that the Q2 budget approval is still pending. They are working on finalizing the numbers and expect to have a revised version ready by tomorrow (June 2nd) morning.\n",
       "\n",
       "I recommend we schedule a call at 10:00 AM tomorrow to review the latest figures and ensure everything is in order for the Mumbai project kickoff. This will also give us an opportunity to discuss any potential risks or concerns before proceeding with vendor onboarding and contract finalization.\n",
       "\n",
       "Please let me know if this time slot works for you, and I'll send out a formal invite to our team members involved in the project.\n",
       "\n",
       "Best regards,\n",
       "Anita Sharma"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f316e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Subject: Immediate Action Required: Software Failure in Client Reporting Tool\n",
    "\n",
    "Dear Karan Desai,\n",
    "\n",
    "I hope you're well.\n",
    "\n",
    "We’ve encountered a critical failure in the Client Reporting Tool (CRT) used by the Finance Analytics Team. Since 9:15 AM today (June 1st), the system has been generating inaccurate reports and throwing multiple data integrity errors for client accounts in the Singapore and Dubai regions.\n",
    "\n",
    "The issue is already affecting daily operations, and we’ve had to pause external reporting to clients such as Zenith Capital and Torus Holdings. As the tool is managed by your team, we request your immediate intervention to investigate and resolve the issue.\n",
    "\n",
    "Please confirm receipt of this email and share an ETA for resolution as soon as possible. If required, we can arrange a quick sync-up call with the impacted stakeholders around 11:00 AM.\n",
    "\n",
    "Thanks for your prompt attention.\n",
    "\n",
    "Best regards,\n",
    "Priya Sinha\n",
    "Senior Analyst – Global Reporting\n",
    "FinWise Consulting Pvt. Ltd.\n",
    "\"\"\"\n",
    "\n",
    "similar_docs = retrieve_similar_docs(query, faiss_index)\n",
    "\n",
    "context = \"\\n---\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "response = generate_answer(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ca6798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Immediate Action Required: Software Failure in Client Reporting Tool\n",
      "\n",
      "Dear Karan Desai,\n",
      "\n",
      "I hope you're well.\n",
      "\n",
      "We’ve encountered a critical failure in the Client Reporting Tool (CRT) used by the Finance Analytics Team. Since 9:15 AM today (June 1st), the system has been generating inaccurate reports and throwing multiple data integrity errors for client accounts in the Singapore and Dubai regions.\n",
      "\n",
      "The issue is already affecting daily operations, and we’ve had to pause external reporting to clients such as Zenith Capital and Torus Holdings. As the tool is managed by your team, we request your immediate intervention to investigate and resolve the issue.\n",
      "\n",
      "Please confirm receipt of this email and share an ETA for resolution as soon as possible. If required, we can arrange a quick sync-up call with the impacted stakeholders around 11:00 AM.\n",
      "\n",
      "Thanks for your prompt attention.\n",
      "\n",
      "Best regards,\n",
      "Priya Sinha\n",
      "Senior Analyst – Global Reporting\n",
      "FinWise Consulting Pvt. Ltd.\n",
      "\n",
      "\n",
      " Response:\n",
      "\n",
      "Subject: Re: Immediate Action Required: Software Failure in Client Reporting Tool\n",
      "\n",
      "Dear Priya,\n",
      "\n",
      "Thank you for reaching out and informing me about the critical failure in the Client Reporting Tool (CRT). I have alerted our development team, and we are currently investigating the issue.\n",
      "\n",
      "I expect a resolution to be in place by 1:00 PM today. In the meantime, I will arrange for an urgent call with the Finance Analytics Team at 11:30 AM to discuss the temporary workaround and any necessary adjustments.\n",
      "\n",
      "Please let me know if you need anything else from us.\n",
      "\n",
      "Best regards,\n",
      "Karan Desai\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63f4538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need your help on the following each day we are delayed in finalising var, pl and positions because the uk must wait for a usd interest rate curves before submitting their data to houston. i am also told that it is really not necessary to wait for this curve and the data could be submitted close of business london. even if there was some minor inaccuracy from this method it would be better than what we have now\n",
      "---\n",
      ". it is strongly recommended that each cm have a representatives that is20 properly trained to handle the option expiration process available beginnin g20 at 415 pm and who will receive the cm3ds reports at the specific times.  it20 is solely the responsibility of the cm to review these reports and to notif y20 the clearing staff immediately of any discrepancies. to obtain the exact time of the availability for each report, clearing20 members should call 212 5137405, access code 702\n",
      "---\n",
      ". backout restore old website files contacts brandon bangerter brian ellis 7133458017 7134466193 raj perubhatla 7133458016 2817889307 impact corp time sun 412001 at 80000 am ct thru sun 412001 at 120000 pm ct sun 412001 at 60000 am pt thru sun 412001 at 100000 am pt sun 412001 at 20000 pm london thru sun 412001 at 60000 pm london outage hr webi update on production servers environments impacted all business objects users as well as users of all hr global applications namely ehronline, gis, gcs,\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42d2e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Subject: Immediate Action Required: Software Failure in Client Reporting Tool\n",
       "\n",
       "Dear Karan Desai,\n",
       "\n",
       "I hope you're well.\n",
       "\n",
       "We’ve encountered a critical failure in the Client Reporting Tool (CRT) used by the Finance Analytics Team. Since 9:15 AM today (June 1st), the system has been generating inaccurate reports and throwing multiple data integrity errors for client accounts in the Singapore and Dubai regions.\n",
       "\n",
       "The issue is already affecting daily operations, and we’ve had to pause external reporting to clients such as Zenith Capital and Torus Holdings. As the tool is managed by your team, we request your immediate intervention to investigate and resolve the issue.\n",
       "\n",
       "Please confirm receipt of this email and share an ETA for resolution as soon as possible. If required, we can arrange a quick sync-up call with the impacted stakeholders around 11:00 AM.\n",
       "\n",
       "Thanks for your prompt attention.\n",
       "\n",
       "Best regards,\n",
       "Priya Sinha\n",
       "Senior Analyst – Global Reporting\n",
       "FinWise Consulting Pvt. Ltd.\n",
       "\n",
       "\n",
       " Response:\n",
       "\n",
       "Subject: Re: Immediate Action Required: Software Failure in Client Reporting Tool\n",
       "\n",
       "Dear Priya,\n",
       "\n",
       "Thank you for reaching out and informing me about the critical failure in the Client Reporting Tool (CRT). I have alerted our development team, and we are currently investigating the issue.\n",
       "\n",
       "I expect a resolution to be in place by 1:00 PM today. In the meantime, I will arrange for an urgent call with the Finance Analytics Team at 11:30 AM to discuss the temporary workaround and any necessary adjustments.\n",
       "\n",
       "Please let me know if you need anything else from us.\n",
       "\n",
       "Best regards,\n",
       "Karan Desai"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7c37444",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Subject: Quick Update on Assigned Task\n",
    "\n",
    "Hi Bapan,\n",
    "\n",
    "Just a quick update on the work assigned:\n",
    "\n",
    "You were tasked with integrating the RAG pipeline using llama3.1:8b and mxbai-embed-large on the filtered Enron dataset. The chunking, embedding, and FAISS indexing have been completed successfully. Initial retrieval tests show accurate results.\n",
    "\n",
    "Please proceed with response generation logic and ensure prompt formatting is handled cleanly. Target completion: by EOD tomorrow (2nd June 2025).\n",
    "\n",
    "Let me know if you hit any blockers.\n",
    "\n",
    "Best,\n",
    "Priya Nair\n",
    "Team Lead – AI Research\n",
    "\"\"\"\n",
    "similar_docs = retrieve_similar_docs(query, faiss_index)\n",
    "\n",
    "context = \"\\n---\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "response = generate_answer(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c6ab11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". after resolution 290 was issued and the regulatory issues were partially resolved, the eol team decided to work on the project again. i am now in the course of adapting the eta, gtc and password application for use in brazil. i will probably have drafts for comments within the next 10 days. i am not sure about the time estimate for completion of the project as a whole. i believe remi can give you a better idea of the schedule\n",
      "---\n",
      "dan, we will have pipeline repairs to do on the mainline in sections 7  8, bet ween stations 6 and 8. pii is running a lapa program on the smart pig resu lts from the pigs ran last september. once the lapa results are complete,  probably within the next 2 weeks, earl chanley will put together a scope an d estimate of work. we don't have a date for the work yet, but probably wi ll be in the mayjune time frame\n",
      "---\n",
      ". when i mentioned this to elena, she was extraordinarily helpful in helping me compile some very useful information on very short notice. she was able to quickly define the scope of the project and gather some pertinent information. because this was not one of her regular assignments, she put in many extra hours to help us out on this project. i just wanted to let you know about a job well done. regards, craig\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18040941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a potential email response to the instruction:\n",
      "\n",
      "Subject: Re: Quick Update on Assigned Task\n",
      "\n",
      "Hi Priya,\n",
      "\n",
      "Thank you for the update. I'm glad to hear that the chunking, embedding, and FAISS indexing have been completed successfully, and initial retrieval tests show accurate results.\n",
      "\n",
      "I've taken note of the target completion time by EOD tomorrow (2nd June 2025). I'll proceed with generating responses using the specified models and ensure that prompt formatting is handled cleanly.\n",
      "\n",
      "If any blockers arise, I'll reach out to you promptly. In the meantime, I have a few questions regarding the next steps:\n",
      "\n",
      "* Are there any specific evaluation metrics or benchmarks we should focus on for this task?\n",
      "* Have we discussed any potential issues with regards to model performance or scalability?\n",
      "\n",
      "Looking forward to hearing back from you.\n",
      "\n",
      "Best,\n",
      "Bapan\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "410566f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a potential email response to the instruction:\n",
       "\n",
       "Subject: Re: Quick Update on Assigned Task\n",
       "\n",
       "Hi Priya,\n",
       "\n",
       "Thank you for the update. I'm glad to hear that the chunking, embedding, and FAISS indexing have been completed successfully, and initial retrieval tests show accurate results.\n",
       "\n",
       "I've taken note of the target completion time by EOD tomorrow (2nd June 2025). I'll proceed with generating responses using the specified models and ensure that prompt formatting is handled cleanly.\n",
       "\n",
       "If any blockers arise, I'll reach out to you promptly. In the meantime, I have a few questions regarding the next steps:\n",
       "\n",
       "* Are there any specific evaluation metrics or benchmarks we should focus on for this task?\n",
       "* Have we discussed any potential issues with regards to model performance or scalability?\n",
       "\n",
       "Looking forward to hearing back from you.\n",
       "\n",
       "Best,\n",
       "Bapan"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c0063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3652661f",
   "metadata": {},
   "source": [
    "#### **Observations:**\n",
    "\n",
    "* The responses generated by the LLM are contextually aligned with the user queries, utilizing information retrieved from the faiss_index.\n",
    "\n",
    "* The generated answers accurately capture key details such as timing, email subjects, important individuals, and semantic cues.\n",
    "\n",
    "* The model maintains good contextual alignment, ensuring the responses stay relevant to the content provided.\n",
    "\n",
    "* However, the quality of the responses is limited in sophistication, likely due to the small size of the underlying knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc29ec",
   "metadata": {},
   "source": [
    "#### **Final Thoughts and Future Work:**\n",
    "\n",
    "* The current implementation relies on in-memory storage and locally installed LLMs and text embedding models, which work well for small-scale testing and development.\n",
    "\n",
    "* To make the solution scalable, it can be extended using a NoSQL database for storing vector embeddings and high-end GPU machines to speed up embedding generation.\n",
    "\n",
    "* By integrating more advanced LLMs and embedding models, we can enable real-time response generation suitable for production-level applications.\n",
    "\n",
    "* APIs can be developed and deployed to serve various business use cases. As a proof of concept, a local API has already been built in this setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcaeac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
