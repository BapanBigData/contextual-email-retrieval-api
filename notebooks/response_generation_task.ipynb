{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b850a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cc6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/filtered_enron_emails.csv')\n",
    "sampled_df = df.sample(frac=0.005, random_state=47).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eeaf942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents with len >= 500: 863\n"
     ]
    }
   ],
   "source": [
    "#Filter emails where body length >= 500 characters\n",
    "filtered_docs = sampled_df['body'].dropna()\n",
    "filtered_docs = filtered_docs[filtered_docs.str.len() >= 500].tolist()\n",
    "\n",
    "# Now filtered_docs contains each email body (≥ 500 chars) as a single document\n",
    "print(f\"Total documents with len >= 500: {len(filtered_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5afb1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,  # slight overlap preserves context\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],  # smart fallback if no newlines\n",
    ")\n",
    "\n",
    "docs = splitter.create_documents(filtered_docs)\n",
    "chunks = [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcea6c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb79d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "def get_ollama_embedding(text, model=\"mxbai-embed-large\"):\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/embeddings\",\n",
    "        json={\"model\": model, \"prompt\": text}\n",
    "    )\n",
    "    return response.json()[\"embedding\"]\n",
    "\n",
    "def embed_chunks_parallel(chunks, max_workers=10):\n",
    "    embeddings = [None] * len(chunks)\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(get_ollama_embedding, chunk): idx\n",
    "            for idx, chunk in enumerate(chunks)\n",
    "        }\n",
    "        for future in tqdm(as_completed(futures), total=len(chunks), desc=\"Embedding chunks\"):\n",
    "            idx = futures[future]\n",
    "            try:\n",
    "                embeddings[idx] = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Chunk {idx} failed: {e}\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb1c9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaEmbeddingFunction(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        embeddings = []\n",
    "        for text in tqdm(texts, desc=\"Embedding via Ollama\"):\n",
    "            response = requests.post(\n",
    "                \"http://localhost:11434/api/embeddings\",\n",
    "                json={\"model\": \"mxbai-embed-large\", \"prompt\": text}\n",
    "            )\n",
    "            embeddings.append(response.json()[\"embedding\"])\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/embeddings\",\n",
    "            json={\"model\": \"mxbai-embed-large\", \"prompt\": text}\n",
    "        )\n",
    "        return response.json()[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding chunks: 100%|██████████| 7600/7600 [32:12<00:00,  3.93it/s]  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "FAISS.from_embeddings() missing 2 required positional arguments: 'text_embeddings' and 'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m chunk_embeddings = embed_chunks_parallel(chunks, max_workers=\u001b[32m10\u001b[39m)  \u001b[38;5;66;03m# Adjust workers for your CPU/GPU\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Step 3: Store in FAISS\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m faiss_index = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Step 4: Save to disk (root folder)\u001b[39;00m\n\u001b[32m     14\u001b[39m faiss_index.save_local(\u001b[33m\"\u001b[39m\u001b[33m../faiss_index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: FAISS.from_embeddings() missing 2 required positional arguments: 'text_embeddings' and 'embedding'"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Step 1: Create documents\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Step 2: Embed in parallel\n",
    "chunk_embeddings = embed_chunks_parallel(chunks, max_workers=10)  # Adjust workers for your CPU/GPU\n",
    "\n",
    "\n",
    "## Below two lines of code have craeted the error\n",
    "\n",
    "# # Step 3: Store in FAISS\n",
    "# faiss_index = FAISS.from_embeddings(embeddings=chunk_embeddings, documents=documents)\n",
    "\n",
    "# # Step 4: Save to disk (root folder)\n",
    "# faiss_index.save_local(\"../faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.docstore.document import Document\n",
    "import numpy as np\n",
    "import faiss \n",
    "\n",
    "# Step 1: Convert to float32 numpy array\n",
    "embedding_vectors = np.array(chunk_embeddings).astype(\"float32\")\n",
    "\n",
    "# Step 2: Create FAISS index\n",
    "dimension = embedding_vectors.shape[1]  # usually 384 or 768 depending on your model\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(embedding_vectors)\n",
    "\n",
    "# Step 3: Wrap documents\n",
    "docstore = InMemoryDocstore(dict(enumerate(documents)))\n",
    "index_to_docstore_id = {i: i for i in range(len(documents))}\n",
    "\n",
    "# Step 4: Create the vectorstore\n",
    "vectorstore = FAISS(\n",
    "    index=faiss_index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id,\n",
    "    embedding_function=embedding_func\n",
    ")\n",
    "\n",
    "# Step 5: Save the index\n",
    "vectorstore.save_local(\"../faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95a15cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7600, 1024)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c73c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedding_func = OllamaEmbeddingFunction()  \n",
    "\n",
    "faiss_index = FAISS.load_local(\n",
    "    folder_path=\"../faiss_index\",\n",
    "    embeddings=embedding_func,\n",
    "    allow_dangerous_deserialization=True  # safe only if file is trusted\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa891227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_similar_docs(query, faiss_index, top_k=3):\n",
    "    query_embedding = get_ollama_embedding(query)\n",
    "    results = faiss_index.similarity_search_by_vector(query_embedding, k=top_k)\n",
    "    return results  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d008fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Generate an email requesting project status update from a colleague\"\n",
    "similar_docs = retrieve_similar_docs(query, faiss_index)\n",
    "\n",
    "context = \"\\n---\\n\".join([doc.page_content for doc in similar_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daa074ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"peter this email will confirm the site visit by your company at the three plants\\n---\\n. thus, it is very important that i hear from you. thank you much kim  forwarded by kim nguyenewcenron on 06242002 1006 am  jeff duff 06212002 0622 pm to kim nguyenewcenronenron cc ronald brzezinskiewcenronenron, kevin cousineauewcenronenron, joe chapmanewcenronenron, clemens wstedeveloptwtdetwtde, markus altenschultedeveloptwtdetwtde subject re autodownload tool kim, first, hollis will be out of the office until further notice. i'll be coordinating his tasks for the time being\\n---\\n. please confirm to me that hal is fully dedicated to this project now and will continue to be until it is completed. i would actually like his to sit with our group at least until the project is complete. i would also like a breakdown of what the other it people listed in the elaboration document will be responsible for, and discuss the 65 day estimation with you. thanks shona\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2e74e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, context):\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant. Use the context below to answer or generate the requested email.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Instruction:\n",
    "    {query}\n",
    "\n",
    "    Response:\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": \"llama3.1:8b\", \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    \n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e62277f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Generate an email requesting project status update from a colleague\"\n",
    "similar_docs = retrieve_similar_docs(query, faiss_index)\n",
    "\n",
    "context = \"\\n---\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "response = generate_answer(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33943f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an email to Peter confirming the site visit and requesting a project status update:\n",
      "\n",
      "Subject: Confirmation of Site Visit and Project Update Request\n",
      "\n",
      "Dear Peter,\n",
      "\n",
      "I hope this email finds you well. I wanted to confirm that your company's site visit at our three plants has been scheduled, as previously discussed.\n",
      "\n",
      "However, I also wanted to touch base with you regarding the ongoing project. As per Kim's earlier request, could you please confirm to me that Hal is fully dedicated to this project and will continue to be involved until its completion? Additionally, would it be possible for him to sit with our group at least until the project is finished?\n",
      "\n",
      "Furthermore, I would appreciate an update on the roles and responsibilities of the other IT personnel listed in the elaboration document. Could you also provide me with a breakdown of what each team member will be responsible for during the project?\n",
      "\n",
      "Lastly, I'd like to discuss the 65-day estimation for this project. Could we schedule a meeting or call at your earliest convenience to review the project timeline and any potential roadblocks?\n",
      "\n",
      "Looking forward to hearing back from you.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "288bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30a31e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is an email to Peter confirming the site visit and requesting a project status update:\n",
       "\n",
       "Subject: Confirmation of Site Visit and Project Update Request\n",
       "\n",
       "Dear Peter,\n",
       "\n",
       "I hope this email finds you well. I wanted to confirm that your company's site visit at our three plants has been scheduled, as previously discussed.\n",
       "\n",
       "However, I also wanted to touch base with you regarding the ongoing project. As per Kim's earlier request, could you please confirm to me that Hal is fully dedicated to this project and will continue to be involved until its completion? Additionally, would it be possible for him to sit with our group at least until the project is finished?\n",
       "\n",
       "Furthermore, I would appreciate an update on the roles and responsibilities of the other IT personnel listed in the elaboration document. Could you also provide me with a breakdown of what each team member will be responsible for during the project?\n",
       "\n",
       "Lastly, I'd like to discuss the 65-day estimation for this project. Could we schedule a meeting or call at your earliest convenience to review the project timeline and any potential roadblocks?\n",
       "\n",
       "Looking forward to hearing back from you.\n",
       "\n",
       "Best regards,\n",
       "\n",
       "[Your Name]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f316e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Generate an email to remind a team member about an upcoming task deadline.\"\n",
    "similar_docs = retrieve_similar_docs(query, faiss_index)\n",
    "\n",
    "context = \"\\n---\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "response = generate_answer(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ca6798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a generated email:\n",
      "\n",
      "Subject: Reminder: Update Your Address Book and Complete Timesheet by Monday, 4pm\n",
      "\n",
      "Dear [Team Member],\n",
      "\n",
      "I wanted to follow up on the memo from Constance Charles regarding the rollout of SAP. As mentioned in the memo, it's essential that we update our address book and complete our timesheets as soon as possible.\n",
      "\n",
      "Could you please make sure to update your address book by providing us with any changes (yes/no) and let us know if you have access to a shared calendar (if yes, which one)? This will help us ensure a smooth transition during the migration process.\n",
      "\n",
      "Additionally, please don't forget to complete your timesheet for the current period. You can input your time online at [http://ehronline.enron.com](http://ehronline.enron.com), but I'll also continue to email you reminders regarding this task.\n",
      "\n",
      "Please confirm by responding to this email that you've updated your address book and completed your timesheet by Monday, 4pm. If there are any issues or concerns, feel free to reach out to me directly.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63f4538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsible for updating your address book no if yes, who do you have access to a shared calendar no if yes, which shared calendar do you have any distribution groups that messaging maintains for you for mass mailings no if yes, please list here please list all notes databases applications that you currently use in our efforts to plan the exact datetime of your migration, we also will need to know what are your normal work hours from 815 to 600 will you be out of the office in the near future\n",
      "---\n",
      "fyi. i sent this monday 4pm if you hear any rumblings\n",
      "---\n",
      ".  with the rollout of sap, you have the ability to go online  httpehronline.enron.com and input your time. i will continue to email for timesheets regardless if you go online. this memo is to inform you to complete your timesheet. quick reminder you may receive your present or previous paychecks  eb 3539a if delivery is not setup to your locationmail stop. thank you for your cooperation constance charles human resources associate  analyst program ext. 35614\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c42d2e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a generated email:\n",
       "\n",
       "Subject: Reminder: Update Your Address Book and Complete Timesheet by Monday, 4pm\n",
       "\n",
       "Dear [Team Member],\n",
       "\n",
       "I wanted to follow up on the memo from Constance Charles regarding the rollout of SAP. As mentioned in the memo, it's essential that we update our address book and complete our timesheets as soon as possible.\n",
       "\n",
       "Could you please make sure to update your address book by providing us with any changes (yes/no) and let us know if you have access to a shared calendar (if yes, which one)? This will help us ensure a smooth transition during the migration process.\n",
       "\n",
       "Additionally, please don't forget to complete your timesheet for the current period. You can input your time online at [http://ehronline.enron.com](http://ehronline.enron.com), but I'll also continue to email you reminders regarding this task.\n",
       "\n",
       "Please confirm by responding to this email that you've updated your address book and completed your timesheet by Monday, 4pm. If there are any issues or concerns, feel free to reach out to me directly.\n",
       "\n",
       "Best regards,\n",
       "\n",
       "[Your Name]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c37444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
