# ğŸ“¬ Enron Email Response Generator & Summarizer (GenAI Assignment)

This repository contains the solution to the **TATA Communications Data Science & GenAI Assignment**. The objective was to build an intelligent system that performs **email summarization**, **response generation**, and **API deployment** using **Retrieval-Augmented Generation (RAG)** and **locally hosted LLMs via Ollama** on the Enron email dataset.

---

## ğŸ§  Solution Overview

We approached the assignment in five tasks:

| Task | Description |
|------|-------------|
| âœ… Task 1 | Dataset Exploration & Preprocessing |
| âœ… Task 2 | Email Summarization using LLM |
| âœ… Task 3 | Contextual Response Generation via RAG |
| âœ… Task 4 | Manual Evaluation of Model Outputs |
| âœ… Task 5 | API Deployment using FastAPI (Bonus) |

---

## ğŸ“‚ Directory Structure

```bash
email-ai-summarizer/
â”‚
â”œâ”€â”€ app/                           # âœ… Task 5: FastAPI app (modular)
â”œâ”€â”€ config/                        # Shared paths and settings
â”œâ”€â”€ engine/                        # Embedding, vector store, prompt templates
â”œâ”€â”€ models/                        # Pydantic models/schemas
â”œâ”€â”€ routers/                       # API routes (summarization, response)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ filtered_enron_emails.csv  # Filtered emails (based on email types, not length)
â”‚
â”œâ”€â”€ faiss_index/                   # ğŸ”’ FAISS vector index (excluded from Git)
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter Notebooks for Tasks 1â€“4
â”‚   â”œâ”€â”€ dataset_exploration_and_preprocessing.ipynb  # Task 1
â”‚   â”œâ”€â”€ email_summarization.ipynb                    # Task 2
â”‚   â””â”€â”€ response_generation_task.ipynb               # Task 3 & 4
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

## âœ… Tasks Summary

### ğŸ” Task 1: Dataset Exploration & Preprocessing
- Performed initial analysis on the Enron dataset.
- Identified **relevant email topics** such as:
  - ğŸ“… Meeting Requests
  - ğŸ“Œ Project Updates
  - ğŸ“ˆ Status Follow-ups
- Filtered and saved emails under `filtered_enron_emails.csv`.
- ğŸ“Œ **Filtering was based on email types, not character length.**

---

### âœ‚ï¸ Task 2: Email Summarization
- Utilized locally hosted LLMs (via **Ollama**) to generate **concise summaries**.
- Focused on clarity, relevance, and capturing essential intent.
- Implemented within `email_summarization.ipynb`.

---


### ğŸ’¬ Task 3: Contextual Response Generation (RAG)
- Built a RAG pipeline using:
  - **Ollama** for embedding + generation
  - **FAISS** for semantic document retrieval
- Only used emails with **length â‰¥ 500 characters** as single chunks (no overlap).
- Vector store built using `chromadb`.
- Integrated in `response_generation_task.ipynb`.

---

### ğŸ“Š Task 4: Evaluation
- Manually verified outputs based on:
  - Relevance
  - Fluency
  - Alignment with context
- All evaluation and debugging steps logged in the notebook.


---

### ğŸš€ Task 5 (Bonus): API Deployment

- Deployed using **FastAPI** with a **modular architecture**.
- Organized under `/app` directory.
- API endpoints support:
  - `/summarize` - Summarize email body
  - `/respond` - Generate email reply based on context


## âš™ï¸ Environment & Setup

- **Python Version**: 3.12.0

- ğŸ“¦ Install requirements:

```bash
pip install -r requirements.txt

ğŸš€ Start FastAPI server:

uvicorn app.main:app --reload


## âš ï¸ Important Notes

| **Item**                      | **Status**                                 |
|------------------------------|---------------------------------------------|
| `data/emails.csv` (original dataset) | âŒ Not pushed to Git                     |
| `faiss_index/`                 | âŒ Not included in Git                    |
| `data/filtered_enron_emails.csv`   | âŒ Not included in Git      |


## ğŸ§± How to Rebuild the RAG Pipeline

1. **Clone the repository and install dependencies:**

```bash
git clone <repo-url>
cd email-ai-summarizer
pip install -r requirements.txt


## ğŸ Final Thoughts

This solution demonstrates how **GenAI** and **local LLMs** can be effectively used for:

- Intelligent summarization  
- Context-aware response generation  
- Scalable deployment using APIs  
